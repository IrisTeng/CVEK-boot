X1 <- X[, c(1:length(label.names[[1]]))]
X2 <- X[, c((length(label.names[[1]]) + 1):
(length(label.names[[1]]) + length(label.names[[2]])))]
data0 <- as.data.frame(cbind(Y, X))
result <- gpr(formula, label.names, data0, method, l, lambda)
# result <- Ensemble(formula, label.names, Kernlist, data0, lambda)
sigma2.n <- result[[1]]
beta0 <- result[[2]]
alpha0 <- result[[3]]
K.gpr <- result[[4]]
noise.hat <- NoiseEstimate(Y, sigma2.n, beta0, alpha0, K.gpr)
mean.Y <- K.gpr %*% alpha0 + beta0
mean(mean.Y)
mean(Y)
method = 'intercept'
result <- gpr(formula, label.names, data0, method, l, lambda)
# result <- Ensemble(formula, label.names, Kernlist, data0, lambda)
sigma2.n <- result[[1]]
beta0 <- result[[2]]
alpha0 <- result[[3]]
K.gpr <- result[[4]]
noise.hat <- NoiseEstimate(Y, sigma2.n, beta0, alpha0, K.gpr)
mean.Y <- K.gpr %*% alpha0 + beta0
mean(mean.Y)
method = 'linear'
result <- gpr(formula, label.names, data0, method, l, lambda)
# result <- Ensemble(formula, label.names, Kernlist, data0, lambda)
sigma2.n <- result[[1]]
beta0 <- result[[2]]
alpha0 <- result[[3]]
K.gpr <- result[[4]]
noise.hat <- NoiseEstimate(Y, sigma2.n, beta0, alpha0, K.gpr)
mean.Y <- K.gpr %*% alpha0 + beta0
mean(mean.Y)
KernelGenerate <-
function(method = NULL, l = 1, p = 2){
# Generate kernel function.
#
# Args:
#   method: A character string indicating which Kernel is to be computed.
#   l: A numeric number indicating the hyperparameter of a specific kernel.
#
# Returns:
#   Kern: A matrix indicating the expected kernel function.
if (method == "intercept")
SE <- function(xp, xq, l, p) 1
else if (method == "linear")
SE <- function(xp, xq, l, p) t(xp) %*% xq
else if (method == "polynomial")
SE <- function(xp, xq, l, p) (t(xp) %*% xq + 1) ^ p
else if (method == "rbf")
SE <- function(xp, xq, l, p) exp(- sum((xp - xq) ^ 2) / (2 * l ^ 2))
else
stop("method must be intercept, linear, polynomial or rbf!")
Kern <- function(X2, X1) apply(X1, 1, function(xp){
apply(X2, 1, function(xq){
SE(xp, xq, l, p)
})
})
return(Kern)
}
Kernlist <- NULL
# intercept kernel
Kernlist <- c(Kernlist, KernelGenerate('intercept'))
# linear kernel
Kernlist <- c(Kernlist, KernelGenerate('linear'))
# polynomial kernel, p = 2
Kernlist <- c(Kernlist, KernelGenerate('polynomial', p = 2))
# polynomial kernel, p = 3
Kernlist <- c(Kernlist, KernelGenerate('polynomial', p = 3))
# polynomial kernel, p = 4
# Kernlist <- c(Kernlist, KernelGenerate('polynomial', p = 4))
# rbf kernel, l = .3
# Kernlist <- c(Kernlist, KernelGenerate('rbf', l = .3))
# rbf kernel, l = .6
Kernlist <- c(Kernlist, KernelGenerate('rbf', l = .6))
# rbf kernel, l = 1
Kernlist <- c(Kernlist, KernelGenerate('rbf', l = 1))
# rbf kernel, l = 2
Kernlist <- c(Kernlist, KernelGenerate('rbf', l = 2))
# rbf kernel, l = 3
Kernlist <- c(Kernlist, KernelGenerate('rbf', l = 3))
Ensemble2 <-
function(formula, label.names, Kernlist,
data = NULL, lambda = exp(seq(-5, 5, 1))){
y <- data[, as.character(attr(terms(formula), "variables"))[2]]
# extract the information from the given formula to construct a true formula
re <- GenericFormula(formula, label.names)
generic.formula0 <- re[[1]]
len <- re[[2]]
# extract design matrix
X <- model.matrix(generic.formula0, data)[, -1]
n <- nrow(X)
# estimation
# D = 10
X1 <- X[, c(1:length(label.names[[1]]))]
X2 <- X[, c((length(label.names[[1]]) + 1):len)]
D <- length(Kernlist)
# lambda.mat <- matrix(0, nrow = D, ncol = n + 1)
error.mat <- matrix(0, nrow = n, ncol = D)
for (d in seq(D)){
Kern <- Kernlist[[d]]
K <- Kern(X1, X1) + Kern(X2, X2)
if (length(lambda) != 1){
lambda0 <- LooCV(y, K, lambda)
K1 <- cbind(1, K)
K2 <- cbind(0, rbind(0, K))
theta <- ginv(lambda0 * K2 + t(K1) %*% K1) %*% t(K1) %*% y
# error.mat[, d] <- y - K1 %*% theta
beta0 <- theta[1]
M <- K %*% ginv(K + lambda0 * diag(n))
error.mat[, d] <- (diag(n) - M) %*% (y - beta0) / diag(diag(n) - M)
}
}
A <- error.mat
B <- rep(0, n)
E <- rep(1, D)
F <- 1
G <- diag(D)
H <- rep(0, D)
u.hat <- lsei(A, B, E = E, F = F, G = G, H = H)$X
return(u.hat)
}
w <- NULL
pb <- txtProgressBar(0, 20, style = 3)
for(method in c('linear', 'polynomial', 'rbf')){
for(i in seq(20)){
setTxtProgressBar(pb, i)
data0 <- OriginalData2(100, label.names, method = method)
w <- rbind(w, Ensemble2(formula, label.names, Kernlist, data = data0))
}
}
setwd('/Users/iristeng/Desktop/KMR/KMR0324/source')
View(w)
w <- as.data.frame(w)
rownames(w) <- paste0(rep(c('linear', 'polynomial', 'rbf'), rep(20, 3)))
rownames(w) <- rep(c('linear', 'polynomial', 'rbf'), rep(20, 3))
length(rep(c('linear', 'polynomial', 'rbf'), rep(20, 3)))
rownames(w) <- c(rep(c('linear', 'polynomial', 'rbf'), rep(20, 3)))
rep(c('linear', 'polynomial', 'rbf'), rep(20, 3))
rownames(w)
rownames(w) <- rep(c('linear', 'polynomial', 'rbf'), rep(20, 3))
View(w)
rownames(w) <-
b <-rep(c('linear', 'polynomial', 'rbf'), rep(20, 3))
rownames(w) <-
b <-rep(c('linear', 'polynomial', 'rbf'), rep(20, 3))
#rownames(w) <-
b <- rep(c('linear', 'polynomial', 'rbf'), rep(20, 3))
rownames(w) <- b
length(rownames(w))
class(w)
w[,1]
rownames(w) <- rep(1:3, rep(20, 3))
rownames(w) <- 1:60
w$generate.method <- rep(c('linear', 'polynomial', 'rbf'), rep(20, 3))
View(w)
colnames(w) <- c('intercept', 'linear', 'polynomial p=2', 'polynomial p=3',
paste0('rbf l=', c(0.6, 1, 2, 3)), 'generate.method')
write.csv(w, file = 'weights.csv')
write.csv(w, file = 'weights.csv', row.names = T)
View(w)
write.csv(w, file = 'weights.csv', row.names = F)
write.csv(w, file = 'weights.csv')
View(w)
data0 <- OriginalData2(100, label.names, method = 'linear', int.effect = 6)
u.new <- Ensemble2(formula, label.names, Kernlist, data = data0)
u.new
data0 <- OriginalData2(100, label.names, method = 'linear', int.effect = 6)
u.new <- Ensemble2(formula, label.names, Kernlist, data = data0)
data0 <- OriginalData2(100, label.names, method = 'linear', int.effect = 5)
u.new <- Ensemble2(formula, label.names, Kernlist, data = data0)
u.new
data0 <- OriginalData2(100, label.names, method = 'linear', int.effect = 3)
u.new <- Ensemble2(formula, label.names, Kernlist, data = data0)
u.new
## without interaction effect=5
w <- NULL
pb <- txtProgressBar(0, 20, style = 3)
for(method in c('linear', 'polynomial', 'rbf')){
for(i in seq(20)){
setTxtProgressBar(pb, i)
data0 <- OriginalData2(100, label.names, method = method, int.effect = 5)
w <- rbind(w, Ensemble2(formula, label.names, Kernlist, data = data0))
}
}
View(w)
w <- as.data.frame(w)
w$generate.method <- rep(c('linear', 'polynomial', 'rbf'), rep(20, 3))
colnames(w) <- c('intercept', 'linear', 'polynomial p=2', 'polynomial p=3',
paste0('rbf l=', c(0.6, 1, 2, 3)), 'generate.method')
write.csv(w, file = 'weights_int.csv')
?rbinom
rbinom
rbinom(1,2,.1)
rbinom(2,3,.1)
?rexp
n <- 1e4
X <- rexp(n, rate = 2)
X.mean <- mean(X)
Z <- n * (X.mean - 1/2) ^ 2
hist(Z)
n <- 1e4
R <- 1e3
Z <- NULL
for(i in seq(R)){
X <- rexp(n, rate = 2)
X.mean <- mean(X)
Z <- c(Z, n * (X.mean - 1/2) ^ 2)
}
hist(Z)
curve(dchisq(seq(0, 2.5, .01), 1), add = T)
?dchisq
?rpois
n <- 1e4
R <- 1e3
Z <- NULL
for(i in seq(R)){
X <- rpois(n, 1)
X.mean <- mean(X)
Z <- c(Z, n * (X.mean - 1) ^ 2)
}
hist(Z)
curve(dchisq(x, 1), add = T)
hist(Z, freq = F)
curve(dchisq(x, 1), add = T, col = 'blue')
hist(Z, freq = F)
curve(dchisq(x, 1), add = T, col = 'blue')
hist(Z, freq = FALSE)
curve(dchisq(x, 1), add = T, col = 'blue')
w <- as.data.frame(round(w, 4))
w <- as.data.frame(round(w[, -1], 4))
w <- as.data.frame(round(w[, -9], 4))
View(w)
write.csv(w, file = 'weights_int.csv')
## without interaction effect
w <- NULL
pb <- txtProgressBar(0, 20, style = 3)
for(method in c('linear', 'polynomial', 'rbf')){
for(i in seq(20)){
setTxtProgressBar(pb, i)
data0 <- OriginalData2(100, label.names, method = method)
w <- rbind(w, Ensemble2(formula, label.names, Kernlist, data = data0))
}
}
w <- as.data.frame(round(w, 4))
w$generate.method <- rep(c('linear', 'polynomial', 'rbf'), rep(20, 3))
colnames(w) <- c('intercept', 'linear', 'polynomial p=2', 'polynomial p=3',
paste0('rbf l=', c(0.6, 1, 2, 3)), 'generate.method')
write.csv(w, file = 'weights.csv')
View(w)
?replicate
sqrt(2/pi)
pchisq(7.5, 2, lower.tail = F)
pchisq(7.5, 2)
pchisq(7.5, 2, lower.tail = FALSE)
MultiScore2 <-
function(formula, label.names,
data = NULL, l = 1, lambda = exp(seq(-5, 5, 1))){
# Compute score tests comparing a fitted model and a more general alternative model.
#
# Args:
#   formula:  A symbolic description of the model to be fitted.
#   label.names: A character string indicating all the interior variables
#                included in each predictor.
#   data: A dataframe to be fitted.
#   method: A character string indicating which Kernel is to be computed.
#   l: A numeric number indicating the hyperparameter of a specific kernel.
#   lambda: A numeric string specifying the range of noise to be chosen.
#           The lower limit of lambda must be above 0.
#
# Returns:
#   test.stat: A numeric number indicating the score test statistics.
# prepare data and estimate under null
y <- data[, as.character(attr(terms(formula), "variables"))[2]]
re <- GenericFormula(formula, label.names)
generic.formula0 <- re[[1]]
len <- re[[2]]
X <- model.matrix(generic.formula0, data)[, -1]
n <- nrow(X)
X1 <- X[, c(1:length(label.names[[1]]))]
X2 <- X[, c((length(label.names[[1]]) + 1):len)]
X12 <- X[, c((len + 1):dim(X)[2])]
# X12 <- NULL
# for (i in 1:length(label.names[[1]])){
#   X12 <- cbind(X12, X1[, i] * X2)
# }
# result <- gpr(Y ~ X1 + X2, label.names, data, method, l, lambda)
result <- Ensemble(Y ~ X1 + X2, label.names, Kernlist, data0, lambda)
sigma2.n <- result[[1]]
beta0 <- result[[2]]
alpha0 <- result[[3]]
K.gpr <- result[[4]]
noise.hat <- NoiseEstimate(y, sigma2.n, beta0, alpha0, K.gpr)
tau.hat <- noise.hat / sigma2.n
# compute score statistic
K0 <- K.gpr
K12 <- X12 %*% t(X12)
V0 <- tau.hat * K0 + noise.hat * diag(n)
test.stat <- tau.hat * t(y - beta0) %*% ginv(V0) %*%
K12 %*% ginv(V0) %*% (y - beta0)
return(test.stat)
}
KernelBoot <-
function(formula, label.names, Kernlist,
data = NULL, l = 1, lambda = exp(seq(-5, 5, 1)), B = 100){
# Compute score tests comparing a fitted model and a more general alternative model.
#
# Args:
#   formula:  A symbolic description of the model to be fitted.
#   label.names: A character string indicating all the interior variables
#                included in each predictor.
#   data: A dataframe to be fitted.
#   method: A character string indicating which Kernel is to be computed.
#   l: A numeric number indicating the hyperparameter of a specific kernel.
#   lambda: A numeric string specifying the range of noise to be chosen.
#           The lower limit of lambda must be above 0.
#   B: The number of bootstrap replicates.
#
# Returns:
#   bs.pvalue: A number indicating the test P-value.
# prepare data
Y <- data[, as.character(attr(terms(formula), "variables"))[2]]
# extract the information from the given formula to construct a true formula
generic.formula0 <-
GenericFormula(formula,label.names)$generic.formula
# extract design matrix
X <- model.matrix(generic.formula0, data)[, -1]
n <- nrow(X)
Xm <- colMeans(X)
p <- ncol(X)
X <- X - rep(Xm, rep(n, p))
Xscale <- drop(rep(1 / n, n) %*% X ^ 2) ^ 0.5
X <- X / rep(Xscale, rep(n, p))
X1 <- X[, c(1:length(label.names[[1]]))]
X2 <- X[, c((length(label.names[[1]]) + 1):
(length(label.names[[1]]) + length(label.names[[2]])))]
data0 <- as.data.frame(cbind(Y, X))
# result <- gpr(formula, label.names, data0, method, l, lambda)
result <- Ensemble(formula, label.names, Kernlist, data0, lambda)
sigma2.n <- result[[1]]
beta0 <- result[[2]]
alpha0 <- result[[3]]
K.gpr <- result[[4]]
noise.hat <- NoiseEstimate(Y, sigma2.n, beta0, alpha0, K.gpr)
mean.Y <- K.gpr %*% alpha0 + beta0
# conduct bootstrap
bs.test <- sapply(1:B, function(k){
Y.star <- mean.Y + rnorm(n, sd = sqrt(noise.hat))
dat <- cbind(Y.star, X)
colnames(dat)[1] <- "Y"
dat <- as.data.frame(dat)
MultiScore2(Y ~ X1 + X2 + X1 * X2, label.names,
data = dat, l, lambda)
})
# assemble test statistic
original.test <-
MultiScore2(Y ~ X1 + X2 + X1 * X2, label.names,
data = data0, l, lambda)
bs.pvalue <- sum(as.numeric(original.test) <= bs.test) / B
return(list(pvalue = bs.pvalue, bs.test = bs.test, original.test = original.test))
}
data <- OriginalData2(100, label.names, "linear")
data <- OriginalData2(200, label.names, "linear")
dd <- KernelBoot(formula, label.names, Kernlist, data)
Ensemble <-
function(formula, label.names, Kernlist,
data = NULL, lambda = exp(seq(-5, 5, 1))){
y <- data[, as.character(attr(terms(formula), "variables"))[2]]
# extract the information from the given formula to construct a true formula
re <- GenericFormula(formula, label.names)
generic.formula0 <- re[[1]]
len <- re[[2]]
# extract design matrix
X <- model.matrix(generic.formula0, data)[, -1]
n <- nrow(X)
# estimation
# D = 10
X1 <- X[, c(1:length(label.names[[1]]))]
X2 <- X[, c((length(label.names[[1]]) + 1):len)]
D <- length(Kernlist)
A.hat <- list()
# lambda.mat <- matrix(0, nrow = D, ncol = n + 1)
error.mat <- matrix(0, nrow = n, ncol = D)
for (d in seq(D)){
Kern <- Kernlist[[d]]
K <- Kern(X1, X1) + Kern(X2, X2)
if (length(lambda) != 1){
lambda0 <- LooCV(y, K, lambda)
K1 <- cbind(1, K)
K2 <- cbind(0, rbind(0, K))
theta <- ginv(lambda0 * K2 + t(K1) %*% K1) %*% t(K1) %*% y
# error.mat[, d] <- y - K1 %*% theta
beta0 <- theta[1]
M <- K %*% ginv(K + lambda0 * diag(n))
error.mat[, d] <- (diag(n) - M) %*% (y - beta0) / diag(diag(n) - M)
A.hat[[d]] <- M
}
}
A <- error.mat
B <- rep(0, n)
E <- rep(1, D)
F <- 1
G <- diag(D)
H <- rep(0, D)
u.hat <- lsei(A, B, E = E, F = F, G = G, H = H)$X
A.est <- u.hat[1] * A.hat[[1]]
for(d in 2:D)
A.est <- A.est + u.hat[d] * A.hat[[d]]
As <- svd(A.est)
K.hat <- As$u %*% diag(As$d / (1 - As$d)) %*% t(As$u)
lambda0 <- LooCV(y, K.hat, lambda)
K1 <- cbind(1, K.hat)
K2 <- cbind(0, rbind(0, K.hat))
theta <- ginv(lambda0 * K2 + t(K1) %*% K1) %*% t(K1) %*% y
beta0 <- theta[1]
alpha <- theta[-1]
return(list(sigma2.n = lambda0, intercept = beta0, alpha = alpha, K = K.hat))
}
dd <- KernelBoot(formula, label.names, Kernlist, data)
res <- Ensemble(formula, label.names, Kernlist, data)
View(res)
# prepare data and estimate under null
y <- data[, as.character(attr(terms(formula), "variables"))[2]]
re <- GenericFormula(formula, label.names)
generic.formula0 <- re[[1]]
len <- re[[2]]
X <- model.matrix(generic.formula0, data)[, -1]
n <- nrow(X)
X1 <- X[, c(1:length(label.names[[1]]))]
X2 <- X[, c((length(label.names[[1]]) + 1):len)]
X12 <- X[, c((len + 1):dim(X)[2])]
dim(X)[2]
# result <- gpr(Y ~ X1 + X2, label.names, data, method, l, lambda)
result <- Ensemble(Y ~ X1 + X2, label.names, Kernlist, data0, lambda)
sigma2.n <- result[[1]]
beta0 <- result[[2]]
alpha0 <- result[[3]]
K.gpr <- result[[4]]
noise.hat <- NoiseEstimate(y, sigma2.n, beta0, alpha0, K.gpr)
lambda.hat <- sigma2.n
beta.hat <- beta0
aplha.hat <- alpha0
K.hat <- K.gpr
n <- nrow(K.hat)
nrow(K.gpr)
# prepare data and estimate under null
y <- data[, as.character(attr(terms(formula), "variables"))[2]]
re <- GenericFormula(formula, label.names)
generic.formula0 <- re[[1]]
len <- re[[2]]
X <- model.matrix(generic.formula0, data)[, -1]
n <- nrow(X)
X1 <- X[, c(1:length(label.names[[1]]))]
X2 <- X[, c((length(label.names[[1]]) + 1):len)]
X12 <- X[, c((len + 1):dim(X)[2])]
# result <- gpr(Y ~ X1 + X2, label.names, data, method, l, lambda)
result <- Ensemble(Y ~ X1 + X2, label.names, Kernlist, data0, lambda)
dim(result[[4]])
length(result[[3]])
length(y)
# prepare data
Y <- data[, as.character(attr(terms(formula), "variables"))[2]]
# extract the information from the given formula to construct a true formula
generic.formula0 <-
GenericFormula(formula,label.names)$generic.formula
# extract design matrix
X <- model.matrix(generic.formula0, data)[, -1]
n <- nrow(X)
Xm <- colMeans(X)
p <- ncol(X)
X <- X - rep(Xm, rep(n, p))
Xscale <- drop(rep(1 / n, n) %*% X ^ 2) ^ 0.5
X <- X / rep(Xscale, rep(n, p))
X1 <- X[, c(1:length(label.names[[1]]))]
X2 <- X[, c((length(label.names[[1]]) + 1):
(length(label.names[[1]]) + length(label.names[[2]])))]
data0 <- as.data.frame(cbind(Y, X))
# result <- gpr(formula, label.names, data0, method, l, lambda)
result <- Ensemble(formula, label.names, Kernlist, data0, lambda)
dim(result[[4]])
sigma2.n <- result[[1]]
beta0 <- result[[2]]
alpha0 <- result[[3]]
K.gpr <- result[[4]]
noise.hat <- NoiseEstimate(Y, sigma2.n, beta0, alpha0, K.gpr)
formula <- Y ~ X1 + X2 + X1 * X2
# prepare data and estimate under null
y <- data[, as.character(attr(terms(formula), "variables"))[2]]
re <- GenericFormula(formula, label.names)
generic.formula0 <- re[[1]]
len <- re[[2]]
X <- model.matrix(generic.formula0, data)[, -1]
n <- nrow(X)
X1 <- X[, c(1:length(label.names[[1]]))]
X2 <- X[, c((length(label.names[[1]]) + 1):len)]
X12 <- X[, c((len + 1):dim(X)[2])]
length(y)
# result <- gpr(Y ~ X1 + X2, label.names, data, method, l, lambda)
result <- Ensemble(Y ~ X1 + X2, label.names, Kernlist, data0, lambda)
# result <- gpr(Y ~ X1 + X2, label.names, data, method, l, lambda)
result <- Ensemble(Y ~ X1 + X2, label.names, Kernlist, data, lambda)
dim(result[[4]])
sigma2.n <- result[[1]]
beta0 <- result[[2]]
alpha0 <- result[[3]]
K.gpr <- result[[4]]
noise.hat <- NoiseEstimate(y, sigma2.n, beta0, alpha0, K.gpr)
tau.hat <- noise.hat / sigma2.n
data <- OriginalData2(200, label.names, "linear")
dd <- KernelBoot(formula, label.names, Kernlist, data)
View(dd)
